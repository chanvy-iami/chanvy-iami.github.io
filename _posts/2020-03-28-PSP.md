---
layout: post
title: Python3爬虫实战
subtitle: 基本库的使用
date: 2020-03-28
author: Weiami
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - Python Spider
---

## 使用requests

### 基本用法

1.实例

```
import requests
r = requests.get('http://www.baidu.com/')
print(type(r))       # 响应类型
print(r.status_code) # 状态码
print(type(r.text))  # 响应体类型
print(r.text)        # 响应内容
print(r.cookies)     # Cookies
```

2.GET请求

* 基本实例

```
import requests
r = requests.get('http://httpbin.org/get')
print(r.text)
```

发起GET请求，返回结果包含请求头、URL等信息。在GET请求中添加额外信息，一般情况下，信息数据用字典存储。

```
import requests
data = {'name': 'germey', 'age': 22}
r = requests.get('http://httpbin.org/get', params=data)
print(r.text)
```

网页返回结果为JSON格式的字符串类型，直接调用json()方法可将其转化为字典。

```
import requests
r = requests.get('http://httpbin.org/get')
print(type(r.text))
print(r.json())
print(type(r.json()))
```

* 抓取网页

```
import requests
import re
headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}
r = requests.get('http://www.zhihu.com/explore', headers=headers)
pattern = re.compile('explore-feed.*?question_link.*?>(.*?)</a>', re.S)
titles = re.findall(pattern, r.text)
print(titles)
```

* 抓取二进制数据

```
import requests
r = requests.get('http://github.com/favicon.ico')
print(r.text)
print(r.content)
with open('favicon.ico', 'wb') as f:
    f.write(r.content)
```

open()方法，第一个参数是文件名称，第二个参数代表以二进制写得形式打开，可向文件中写入二进制数据。

* 添加headers

通过headers参数来传递头信息，有些页面如果不传递headers，就不能正常请求。

3.POST请求

```
import requests
data = {'name': 'germey', 'age': '22'}
r = requests.post('http://httpbin.org/post', data=data)
print(r.text)
```

form部分是提交的数据，证明POST请求成功发送了。

4.响应

发送请求后，得到的就是响应。

```
import requests
r = requests.get('http://www.baidu.com')
print(type(r.status_code), r.status_code)
print(type(r.headers), r.headers)
print(type(r.cookies), r.cookies)
print(type(r.url), r.url)
print(type(r.history), r.history)
```

状态码常用来判断请求是否成功，而requests提供一个内置的状态码查询对象requests.codes。

```
import requests
r = requests.get('http://www.baidu.com')
exit() if not r.status_code == requests.codes.ok else print('Request Successfully')
```

通过比较返回码和内置的成功返回码，保证请求得到正常响应，输出成功请求的信息，否则程序终止。requests.codes.ok对应成功状态码200，其他条件码请参考《Python3网络爬虫开发实战》。

### 高级用法

1.文件上传

requests可以模拟提交一些数据。

```
import requests
files = {'file': open('favicon.ico', 'rb')}
r = requests.post('http://httpbin.org/post', files=files)
print(r.text)
```

文件上传部分会单独有一个files字段来标识。

2.Cookies

获取和设置Cookies。

```
import requests
r = requests.get('http://www.baidu.com')
print(r.cookies)
for key, value in r.cookies.items():
    print(key + '=' + value)
```

3.会话维持

利用Session可模拟同一个会话而不担心cookies的问题，通常用于模拟登录成功之后的下一步操作。

```
import requests
requests.get('http://httpbin.org/cookies/set/number/123456789')
r = requests.get('http://httpbin.org/cookies')
print(r.text)

s = requests.Session()
s.get('http://httpbin.org/cookies/set/number/123456789')
r = s.get('http://httpbin.org/cookies')
print(r.text)
```

4.SSL证书验证

requests提供证书验证功能，发送HTTP请求时会检查SSL证书，使用verify参数控制是否检查证书，无verify参数时默认为True。

```
import requests
response = requests.get('http://www.12306.cn')
print(response.status_code)
response = requests.get('http://www.12306.cn', verify=False)
print(response.status_code)   # 出现警告
from requests.packages import urllib3
urllib3.disable_warnings()
response = requests.get('http://www.12306.cn', verify=False)
print(response.status_code)   # 忽略警告
```

5.代理设置

* 使用proxies参数设置代理

```
import requests
proxies = {'http': 'http://10.10.1.10:3128', 'https': 'http://10.10.1.10:1080'}
requests.get('https://www.taobao.com', proxies=proxies)
```

* 使用http://user:password@host:port语法设置代理

```
import requests
proxies = {'http': 'http://user:password@10.10.1.10:3128'}
requests.get('https://www.taobao.com', proxies=proxies)
```

* 出HTTP代理外，requests还支持SOCKS协议的代理

安装socks库之后可以使用。

```
import requests
proxies = {'http': 'socks5://user:password@host:port', 'https': 'socks5://user:password@host:port'}
requests.get('https://www.taobao.com', proxies=proxies)
```

6.超时设置

使用timeout参数。

```
import requests
r = requests.get('https://www.taobao.com', timeout = 1)
print(r.status_code)
```

永久等待，将timeout设置为None，留空默认为None。

```
r = requests.get('https://www.taobao.com', timeout = None)
r = requests.get('https://www.taobao.com')
```

7.身份认证

requests自带身份认证功能。

```
import requests
from requests.auth import HTTPBasicAuth  # 使用HTTPBasicAuthor类
r = requests.get('http://localhost:5000', auth=HTTPBasicAuth('username', 'password'))
print(r.status_code)
```

使用HTTPBasicAuth类繁琐，直接使用元组。

```
import requests
r = requests.get('http://localhost:5000', auth=('username', 'password'))
print(r.status_code)
```

安装oauth包进行OAuth认证。

8.Prepared Request

首先构造一个Request对象，然后调用Session的prepare_request()方法将其转换为一个Prepared Request对象，然后调用send()方法发送即可。